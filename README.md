# Identity-Based Federated LearningThis repository contains an implementation of a federated learning system that incorporates Identity-Based Cryptography (IBC) for secure client authentication and message integrity checks. This system is designed to provide a distributed machine learning environment with enhanced security features.## Files Overview (Src)### Aggregator.py- Main orchestrator of the federated learning process- Manages client connections and authentication using IBI and IBS- Implements Byzantine-resistant aggregation methods (Krum and Trimmed Mean)- Handles training rounds and client synchronization### TNC_IBI.py- Implements the Identity-Based Identification (TNC-IBI) scheme in accordance with solution proposed in https://doi.org/10.3390/sym13081330- Provides key generation, signing, and verification methods for client authentication- Based on TNC signature and incorporates Kurosawa-Heng transform as an adaptation for IBI.### LB_IBS.py- Implements the Lattice-Based Identity-Based Signature (LB-IBS) scheme in accordance with https://doi.org/10.1007/978-981-97-8801-9_11- Offers system setup, key generation, and signature methods- Utilizes lattice-based cryptography for enhanced security### NeuralNetwork.py- Defines the neural network architecture used in the federated learning process- Implements a simple feedforward neural network with dropout layersThe configuration of the neural network is as follows:- Binary Classification- Layer size: input size * 8 * 16 * 8 * 1 - Dropout: p = 0.5 between 8 * 16 and 16 * 8, p=0.2 between 8 * 1- Learning rate = 0.01- Batch Size = 32### CSVData.py- Utility class for handling CSV datasets- Implements a PyTorch Dataset for easy data loading and manipulation### client.py-  Source code for a **benign** client (no attacks injected over the transferred weights)### client_m.py- Source code for **malicious** client, used to simulate adaptive adversaries- After disconnection, attempts to reconnect with a different attack strategy.The attacks implemented and ready for use:- Gaussian Noise (atk_opt = 0)- A Little is Enough (ALIE, atk_opt = 1)- Inner Product Manipulation (IPM, atk_opt = 2)## Files Overview (optional and bash)### DataPreprocessing.py- An additional file for quick data pre-processing.### StartClients(_m).sh- Bash script running multiple threads of simulated clients that initialize *n* number of clients (specified in files main loop)- Adapted for simulations, runs on Linux threads## Key Features- Secure client authentication using Identity-Based Cryptography (IBI and IBS)- Byzantine-resistant aggregation with Krum and Trimmed Mean algorithms- Flexible neural network architecture- Support for multiple clients in the federated learning process, along with simulation environment for adversarial activities.- Result tracking and saving for analysis## Usage1. Ensure all dependencies are installed (PyTorch, ecdsa, pycryptodome)2. Run the Aggregator by executing `Aggregator.py` on a separate machine3. Connect clients to the Aggregator (you may use a bash script StartClients and StartClients_m if one needs to simulate multiple clients over threads)4. The system will manage training rounds and model updates automatically## Security Considerations- Uses both TNC-IBI and LB-IBS for enhanced security and authentication- Cryptographic parameters are set for a security level of 90 bits (LB-IBS)- Implementation over ECC (TNC-IBI)- Client identities are verified before allowing participation in the learning process## NoteThis codebase is intended for research and educational purposes. Not intended for production deployment.